
# Conditional Variational Autoencoder for MNIST and CIFAR10

This is the pytorch implementation of:
- Conditional Variational Autoencoder (CVAE)

which was introduced in [Leaning Structured Output Representation Using Deep Conditional Generative Models](https://papers.nips.cc/paper/5775-learning-structured-output-representation-using-deep-conditional-generative-models) by Sohn et al.

# Structure
## Model types

<table align='center'>
<tr align='center'>
	<td> <strong>Encoder</strong> </td>
	<td colspan=3>  Gaussian </td>
</tr>
<tr align='center'>
	<td> <strong>Decoder</strong> </td>
	<td colspan=2> Gaussian </td>
	<td> Bernoulli </td>
</tr>
<tr align='center'>
	<td> <strong>Model output</strong> </td>
	<td> Mean, Std</td>
	<td> Mean</td>
	<td> Probability </td>
</tr>
<tr align='center'>
	<td> <strong>Supported dataset</strong> </td>
	<td colspan=2> MNIST, CIFAR10</td>
	<td> MNIST</td>
</tr>
<tr align='center'>
	<td> <strong>Input image</strong> </td>
	<td colspan=2> As is </td>
	<td>  Binarized</td>
</tr>
</table>

## Network Structure

Refer to [```model.py```](/Implementations/Conditional-Variational-Autoencoder/model.py). At ```__init__```, I annotated the shape change of the input every layer.

MNIST and CIFAR10 both have 10 classes. The labels are first transformed into onehot vectors each of size 10 and concatenated to the input of both the encoder and the decoder.

# Results
## MNIST Reconstruction

Training specs:
- Initial learning rate ```1e-4``` with ```torch.optim.Adam``` optimizer
- Learning rate scheduled with ```torch.optim.lr_scheduler.ReduceLROnPlateau``` by mean training loss
- Batch size ```64```

With **Bernoulli decoder** and **2-D** latent variable:

<table align='center'>
<tr align='center'>
    <td> Input image </td>
</tr>
<tr align='center'>
    <td><img src = '/Implementations/Conditional-Variational-Autoencoder/results/Binarized-truth.png' height = '200px'> </td>
</tr>
<tr align='center'>
	<td> Epoch 1 </td>
    <td> Epoch 2  </td>
    <td> Epoch 5 </td>
    <td> Epoch 10 </td>
</tr>
<tr align='center'>
	<td><img src = '/Implementations/Conditional-Variational-Autoencoder/results/Mean-reconstruction-Bernoulli-z2-e001.png' height = '200px'>
    <td><img src = '/Implementations/Conditional-Variational-Autoencoder/results/Mean-reconstruction-Bernoulli-z2-e002.png' height = '200px'>
    <td><img src = '/Implementations/Conditional-Variational-Autoencoder/results/Mean-reconstruction-Bernoulli-z2-e005.png' height = '200px'>
    <td><img src = '/Implementations/Conditional-Variational-Autoencoder/results/Mean-reconstruction-Bernoulli-z2-e010.png' height = '200px'>
</tr>
<tr align='center'>
	<td> Epoch 20 </td>
    <td> Epoch 30  </td>
    <td> Epoch 40 </td>
    <td> Epoch 50 </td>
</tr>
<tr align='center'>
	<td><img src = '/Implementations/Conditional-Variational-Autoencoder/results/Mean-reconstruction-Bernoulli-z2-e020.png' height = '200px'>
    <td><img src = '/Implementations/Conditional-Variational-Autoencoder/results/Mean-reconstruction-Bernoulli-z2-e030.png' height = '200px'>
    <td><img src = '/Implementations/Conditional-Variational-Autoencoder/results/Mean-reconstruction-Bernoulli-z2-e040.png' height = '200px'>
    <td><img src = '/Implementations/Conditional-Variational-Autoencoder/results/Mean-reconstruction-Bernoulli-z2-e050.png' height = '200px'>
</tr>
</table>

By 'mean reconstruction' I mean that the images were created by directly interpreting the output Bernoulli distribution parameter ```p``` as the pixel intensity. I also sampled images from the multivariate Bernoulli distribution, but the results weren't that pretty. Check them out at the ```/results``` folder.

The change of 2-D latent variables generated by the first test batch during 50 epochs:

<img src = '/Implementations/Conditional-Variational-Autoencoder/results/latent-variable.gif' height = '350px'>

## MNIST Generation

With **2-D uniformly sampled** latent variables:

<table align='center'>
<tr align='center'>
    <td><img src = '/Implementations/Conditional-Variational-Autoencoder/results/uniform-generation-MNIST-400-0.png' height = '350px'></td>
    <td><img src = '/Implementations/Conditional-Variational-Autoencoder/results/uniform-generation-MNIST-400-1.png' height = '350px'></td>
</tr>
<tr align='center'>
    <td><img src = '/Implementations/Conditional-Variational-Autoencoder/results/uniform-generation-MNIST-400-2.png' height = '350px'></td>
    <td><img src = '/Implementations/Conditional-Variational-Autoencoder/results/uniform-generation-MNIST-400-3.png' height = '350px'></td>
</tr>
<tr align='center'>
    <td><img src = '/Implementations/Conditional-Variational-Autoencoder/results/uniform-generation-MNIST-400-4.png' height = '350px'></td>
    <td><img src = '/Implementations/Conditional-Variational-Autoencoder/results/uniform-generation-MNIST-400-5.png' height = '350px'></td>
</tr>
<tr align='center'>
    <td><img src = '/Implementations/Conditional-Variational-Autoencoder/results/uniform-generation-MNIST-400-6.png' height = '350px'></td>
    <td><img src = '/Implementations/Conditional-Variational-Autoencoder/results/uniform-generation-MNIST-400-7.png' height = '350px'></td>
</tr>
<tr align='center'>
    <td><img src = '/Implementations/Conditional-Variational-Autoencoder/results/uniform-generation-MNIST-400-8.png' height = '350px'></td>
    <td><img src = '/Implementations/Conditional-Variational-Autoencoder/results/uniform-generation-MNIST-400-9.png' height = '350px'></td>
</tr>
</table>

With **2-D randomly sampled** latent variables:

<table align='center'>
<tr align='center'>
    <td><img src = '/Implementations/Conditional-Variational-Autoencoder/results/random-generation-MNIST-400-0.png' height = '350px'></td>
    <td><img src = '/Implementations/Conditional-Variational-Autoencoder/results/random-generation-MNIST-400-1.png' height = '350px'></td>
</tr>
<tr align='center'>
    <td><img src = '/Implementations/Conditional-Variational-Autoencoder/results/random-generation-MNIST-400-2.png' height = '350px'></td>
    <td><img src = '/Implementations/Conditional-Variational-Autoencoder/results/random-generation-MNIST-400-3.png' height = '350px'></td>
</tr>
<tr align='center'>
    <td><img src = '/Implementations/Conditional-Variational-Autoencoder/results/random-generation-MNIST-400-4.png' height = '350px'></td>
    <td><img src = '/Implementations/Conditional-Variational-Autoencoder/results/random-generation-MNIST-400-5.png' height = '350px'></td>
</tr>
<tr align='center'>
    <td><img src = '/Implementations/Conditional-Variational-Autoencoder/results/random-generation-MNIST-400-6.png' height = '350px'></td>
    <td><img src = '/Implementations/Conditional-Variational-Autoencoder/results/random-generation-MNIST-400-7.png' height = '350px'></td>
</tr>
<tr align='center'>
    <td><img src = '/Implementations/Conditional-Variational-Autoencoder/results/random-generation-MNIST-400-8.png' height = '350px'></td>
    <td><img src = '/Implementations/Conditional-Variational-Autoencoder/results/random-generation-MNIST-400-9.png' height = '350px'></td>
</tr>
</table>

## CIFAR10 Reconstruction

With **Gaussian decoder** and **50-D** latent variable:

<table align='center'>
<tr align='center'>
    <td> Input image </td>
</tr>
<tr align='center'>
    <td> <img src = "/Implementations/Conditional-Variational-Autoencoder/results/Truth-Gaussian.png" height = '200px'> </td>
</tr>
<tr align='center'>
    <td> Epoch 1 </td>
    <td> Epoch 5 </td>
    <td> Epoch 25 </td>
</tr>
<tr align='center'>
    <td><img src = '/Implementations/Conditional-Variational-Autoencoder/results/Mean-reconstruction-Gaussian-z50-e001.png' height = '200px'> </td>
    <td><img src = '/Implementations/Conditional-Variational-Autoencoder/results/Mean-reconstruction-Gaussian-z50-e005.png' height = '200px'> </td>
    <td><img src = '/Implementations/Conditional-Variational-Autoencoder/results/Mean-reconstruction-Gaussian-z50-e025.png' height = '200px'> </td>
</tr>
<tr align='center'>
	<td> Epoch 50 </td>
    <td> Epoch 75  </td>
    <td> Epoch 100 </td>
</tr>
<tr align='center'>
	<td><img src = '/Implementations/Conditional-Variational-Autoencoder/results/Mean-reconstruction-Gaussian-z50-e050.png' height = '200px'> </td>
	<td><img src = '/Implementations/Conditional-Variational-Autoencoder/results/Mean-reconstruction-Gaussian-z50-e075.png' height = '200px'> </td>
	<td><img src = '/Implementations/Conditional-Variational-Autoencoder/results/Mean-reconstruction-Gaussian-z50-e100.png' height = '200px'> </td>
</tr>
</table>

# Usage
## Prerequisites

1. Pytorch and torchvision
2. Packages: numpy, matplotlib

## Execution

Command line:
```bash
python train.py -d 'MNIST' -t 'Bernoulli' -s False -e 10 -b 64 -lr 3e-4 -z 10 -p 1 -rp 'saved_model/path' -re 20
```

Jupyter notebook:
```python
from train import main
%matplotlib inline

main(dataset='MNIST', decoder_type='Bernoulli', model_sigma=False, epochs=10, batch_size=64, learning_rate=3e-4, latent_dim=10, print_every=1, resume_path='saved_model/path', resume_epoch=20)
```

## Arguments
Every argument is optional, and has a default value defined at ```arguments.py```.

- ```--dataset, -d```: 'MNIST' or 'CIFAR10'. *Default*: - ```'MNIST'```  
- ```--decoder_type, -t```: 'Bernoulli' or 'Gaussian'. *Default*: ```'Bernoulli'```
- ```--model_sigma, -s```: In case of Gaussian decoder, whether to model the standard deviation. *Default*: ```False```
- ```--epochs, -e```: Number of epochs to train. *Default*: ```10```
- ```--batch_size, -b```: Size of batch size at training/testing. *Default*: ```64```
- ```--learning_rate, -lr```: Learning rate. *Default*: ```3e-4```
- ```--latent_dim, -z```: Dimension of the latent variable. *Default*: ```10```
- ```--print_every, -p```: How often to print training progress. *Default*: ```1```
- ```--resume_path, -rp```: In case you want to resume training from a saved model, provide its path here.
- ```--resume_epoch, -re```: Number of epochs already trained for the saved model. *Default*: ```0```

